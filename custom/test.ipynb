{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import tensor\n",
    "from torchlightning import Network\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/admin/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "/Users/admin/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 139   \n",
      "---------------------------------------\n",
      "139       Trainable params\n",
      "0         Non-trainable params\n",
      "139       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "/Users/admin/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/admin/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf0039f8b7594dfcb4a96ec02d19dd89"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[\"data\"], data[\"target\"], test_size=0.2)\n",
    "train_data = TensorDataset(tensor(x_train, dtype=torch.float32), tensor(y_train, dtype=torch.long))\n",
    "test_data = TensorDataset(tensor(x_test, dtype=torch.float32), tensor(y_test, dtype=torch.long))\n",
    "train_loader = DataLoader(train_data, batch_size=1024, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1024, pin_memory=True)\n",
    "\n",
    "model = Network()\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9667)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "encoder = model.encoder\n",
    "evaluator = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "x, y = test_data.tensors\n",
    "y_pred = encoder(x)\n",
    "print(evaluator(torch.argmax(y_pred, dim=1), y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "No `test_step()` method defined to run `Trainer.test`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMisconfigurationException\u001B[0m                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:794\u001B[0m, in \u001B[0;36mTrainer.test\u001B[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001B[0m\n\u001B[1;32m    792\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_unwrap_optimized(model)\n\u001B[1;32m    793\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 794\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_test_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 38\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     41\u001B[0m     trainer\u001B[38;5;241m.\u001B[39m_call_teardown_hook()\n",
      "File \u001B[0;32m~/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:842\u001B[0m, in \u001B[0;36mTrainer._test_impl\u001B[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001B[0m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tested_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt_path  \u001B[38;5;66;03m# TODO: remove in v1.8\u001B[39;00m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;66;03m# run test\u001B[39;00m\n\u001B[0;32m--> 842\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtesting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1038\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_connector\u001B[38;5;241m.\u001B[39m_attach_model_callbacks()\n\u001B[1;32m   1036\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_connector\u001B[38;5;241m.\u001B[39m_attach_model_logging_functions()\n\u001B[0;32m-> 1038\u001B[0m \u001B[43mverify_loop_configurations\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;66;03m# hook\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m log\u001B[38;5;241m.\u001B[39mdetail(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: preparing data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:47\u001B[0m, in \u001B[0;36mverify_loop_configurations\u001B[0;34m(trainer)\u001B[0m\n\u001B[1;32m     45\u001B[0m     __verify_eval_loop_configuration(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;241m==\u001B[39m TrainerFn\u001B[38;5;241m.\u001B[39mTESTING:\n\u001B[0;32m---> 47\u001B[0m     \u001B[43m__verify_eval_loop_configuration\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;241m==\u001B[39m TrainerFn\u001B[38;5;241m.\u001B[39mPREDICTING:\n\u001B[1;32m     49\u001B[0m     __verify_eval_loop_configuration(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.conda/envs/EE2211/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:131\u001B[0m, in \u001B[0;36m__verify_eval_loop_configuration\u001B[0;34m(model, stage)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;66;03m# -----------------------------------\u001B[39;00m\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;66;03m# verify model has an eval_step\u001B[39;00m\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;66;03m# -----------------------------------\u001B[39;00m\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_step:\n\u001B[0;32m--> 131\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()` method defined to run `Trainer.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer_method\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mMisconfigurationException\u001B[0m: No `test_step()` method defined to run `Trainer.test`."
     ]
    }
   ],
   "source": [
    "trainer.test(model=model, dataloaders=test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
